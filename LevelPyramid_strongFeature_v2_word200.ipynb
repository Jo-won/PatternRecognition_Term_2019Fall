{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LevelPyramid_strongFeature_v2_word200.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jo-won/PatternRecognition_Term_2019Fall/blob/master/LevelPyramid_strongFeature_v2_word200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTlv65HbIEh0",
        "colab_type": "code",
        "outputId": "694be66e-f293-49bd-8d1f-6d7a1dccc926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "# Downgrade cv\n",
        "!yes | pip uninstall opencv-python\n",
        "!yes | pip uninstall opencv-contrib-python\n",
        "!yes | pip install opencv-python==3.4.2.16\n",
        "!yes | pip install opencv-contrib-python==3.4.2.16\n",
        "!pip install kmc2\n",
        "! pip install cupy-cuda100\n",
        "\n",
        "#mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling opencv-python-4.1.2.30:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/opencv_python-4.1.2.30.dist-info/*\n",
            "Proceed (y/n)?   Successfully uninstalled opencv-python-4.1.2.30\n",
            "Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/opencv_contrib_python-4.1.2.30.dist-info/*\n",
            "Proceed (y/n)?   Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.17.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 64.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.17.4)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n",
            "Collecting kmc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/a2/42b2dd4fa0c425912c03222dd443f1d6aceed410a29467d1e5d8989c72f1/kmc2-0.1.tar.gz (102kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kmc2) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from kmc2) (1.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from kmc2) (0.21.3)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->kmc2) (0.14.0)\n",
            "Building wheels for collected packages: kmc2\n",
            "  Building wheel for kmc2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kmc2: filename=kmc2-0.1-cp36-cp36m-linux_x86_64.whl size=252215 sha256=701d84eab8c66c04e27980a37847c45f4c932afafa485ce2086d4bb664e0ef42\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/ba/f0/4c8b421be72d4f2d1a93233c2f6f591e7d8b0bda05a1f4616f\n",
            "Successfully built kmc2\n",
            "Installing collected packages: nose, kmc2\n",
            "Successfully installed kmc2-0.1 nose-1.3.7\n",
            "Collecting cupy-cuda100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/3a/bf66277c1230a9cf3c26afa5b5fabc9fceb2e63f914cf5f4d59d574ac968/cupy_cuda100-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (382.9MB)\n",
            "\u001b[K     |████████████████████████████████| 382.9MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (0.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (1.17.4)\n",
            "Installing collected packages: cupy-cuda100\n",
            "Successfully installed cupy-cuda100-7.0.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNhiBX6Iezc",
        "colab_type": "code",
        "outputId": "bb83aac1-aaf4-4196-ddf1-2fbf4f060b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# Kaggle API Renewal. It should be version 1.5.6\n",
        "\n",
        "!ls -lha kaggle.json\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "! mkdir -p ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle -v\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'kaggle.json': No such file or directory\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Collecting kaggle==1.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=7166bf6a438b91727d1574c2870677b588f696704a18abcfa0aad1cbe0ea0795\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 149, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "37nlyDUe62et",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.cluster import KMeans\n",
        "import copy\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import kmc2\n",
        "from sklearn.cluster import MiniBatchKMeans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRb1o88t62ew",
        "outputId": "6a77ea49-8079-4920-aadb-d75e07d1bfea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "! ls\n",
        "stepSize = 8\n",
        "train_background = False\n",
        "use_precompute = True\n",
        "datasetPath = \"/content/drive/My Drive/dataset/2019-ml-finalproject/\"\n",
        "datasetTrainPath = os.path.join(datasetPath + 'train')\n",
        "datasetTestPath = os.path.join(datasetPath + 'testAll_v2')\n",
        "className = os.listdir(datasetTrainPath)\n",
        "className.sort()\n",
        "classNameDict = dict(zip(range(0,len(className)), className))\n",
        "print(className)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n",
            "['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vn58qfA962e5",
        "outputId": "509b89c3-0450-464d-d7d3-3c6b4bd8133e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# load training dataset\n",
        "\n",
        "trainDataset = []\n",
        "trainLabel = []\n",
        "\n",
        "lab = -1\n",
        "for i, name in tqdm.tqdm(enumerate(className)):\n",
        "\n",
        "    if className[i-1] != className[i]:\n",
        "        lab+=1\n",
        "    filename = os.listdir(os.path.join(datasetTrainPath+'/'+name))\n",
        "    \n",
        "    if train_background is False: # except background\n",
        "    \n",
        "        if i==0:\n",
        "            continue\n",
        "    \n",
        "    for img in filename:\n",
        "\n",
        "        if use_precompute is False:\n",
        "            data = cv2.resize(cv2.imread(datasetTrainPath+'/'+name+'/'+img), (256,256), interpolation = cv2.INTER_LINEAR)\n",
        "            data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "            trainDataset.append(cv2.GaussianBlur(data,(3,3),(stepSize/3)**2-0.25))\n",
        "\n",
        "        trainLabel.append(lab)\n",
        "\n",
        "if use_precompute is False:\n",
        "\n",
        "    trainDataset = np.asarray(trainDataset)\n",
        "    print(trainDataset.shape)\n",
        "\n",
        "trainLabel = np.asarray(trainLabel)\n",
        "print(trainLabel.shape)\n",
        "\n",
        "if use_precompute is False:\n",
        "    np.savez('/content/drive/My Drive/Colab Notebooks/pattern/repo/dataset/datatrainG', trainDataset=trainDataset, trainLabel=trainLabel)\n",
        "else:\n",
        "    savez_load = np.load('/content/drive/My Drive/Colab Notebooks/pattern/repo/dataset/datatrainG.npz')\n",
        "    trainDataset = savez_load['trainDataset']\n",
        "    trainLabel = savez_load['trainLabel']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102it [00:14,  6.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3030,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAynBwkB62e7",
        "outputId": "e6f05714-a4e6-4148-f2a4-506bd35699d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load test dataset\n",
        "\n",
        "testDataset = []\n",
        "filename = os.listdir(os.path.join(datasetTestPath))\n",
        "filename.sort()\n",
        "\n",
        "for img in tqdm.tqdm(filename):\n",
        "\n",
        "    if use_precompute is False:\n",
        "        data = cv2.resize(cv2.imread(datasetTestPath+'/'+img), (256,256), interpolation = cv2.INTER_LINEAR)\n",
        "        data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "        testDataset.append(cv2.GaussianBlur(data,(3,3),(stepSize/3)**2-0.25))\n",
        "\n",
        "if use_precompute is False:\n",
        "    testDataset = np.asarray(testDataset)\n",
        "    print(testDataset.shape)\n",
        "\n",
        "if use_precompute is False:\n",
        "    np.savez('/content/drive/My Drive/Colab Notebooks/pattern/repo/dataset/datatestG', testDataset=testDataset)\n",
        "else:\n",
        "    savez_load = np.load('/content/drive/My Drive/Colab Notebooks/pattern/repo/dataset/datatestG.npz')\n",
        "    testDataset = savez_load['testDataset']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1692/1692 [00:00<00:00, 1421057.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiKIBmMDjaU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute dense SIFT \n",
        "def computeSIFT_(data,step_size):\n",
        "    x = []\n",
        "    for i in tqdm.tqdm(range(0, len(data)), desc = \"Processing\"):\n",
        "        sift = cv2.xfeatures2d.SIFT_create()\n",
        "        img = data[i]\n",
        "\n",
        "\n",
        "        kp = [cv2.KeyPoint(x, y, step_size) for x in range(0, img.shape[0], step_size) for y in range(0, img.shape[1], step_size)]\n",
        "        dense_feat = sift.compute(img, kp)\n",
        "        if np.linalg.norm(np.array(dense_feat[1]))>1.0:\n",
        "            normalizeFeat = np.array(dense_feat[1])/float(np.linalg.norm(np.array(dense_feat[1])))\n",
        "        x.append(normalizeFeat)\n",
        "        \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Un7shHCF62fC",
        "colab": {}
      },
      "source": [
        "feats_save_path = '/content/drive/My Drive/Colab Notebooks/pattern/repo/pyramid/'\n",
        "\n",
        "if os.path.isfile(feats_save_path + 'feats_save_G.npz'):\n",
        "    savez_load = np.load(feats_save_path + 'feats_save_G.npz')\n",
        "    trainFeats = savez_load['train']\n",
        "    testFeats = savez_load['test']\n",
        "    \n",
        "else:\n",
        "    trainFeats = computeSIFT_(trainDataset, stepSize)\n",
        "    testFeats = computeSIFT_(testDataset, stepSize)\n",
        "    np.savez(feats_save_path + 'feats_save_G', train=trainFeats, test=testFeats)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHWVvLpYFOUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load\n",
        "if os.path.isfile(feats_save_path + 'codeword_kmeans_G.npz') and os.path.isfile(feats_save_path + 'kmeans_G.joblib'):\n",
        "    savez_load = np.load(feats_save_path + 'codeword_kmeans_G.npz')\n",
        "    codebook = savez_load['codeword']\n",
        "    codebooksize = savez_load['codebooksize']\n",
        "    kmeans = load(feats_save_path + 'kmeans_G.joblib') \n",
        "else:\n",
        "    codebooksize = 600\n",
        "    seeding = kmc2.kmc2(np.array(trainFeats).reshape(-1,128), codebooksize)\n",
        "    kmeans = KMeans(codebooksize, init=seeding).fit(np.array(trainFeats).reshape(-1,128))\n",
        "    codebook = kmeans.cluster_centers_\n",
        "\n",
        "    codeword_save_path = \"/content/drive/My Drive/Colab Notebooks/pattern/repo/pyramid/\"\n",
        "    print(codebook.shape)\n",
        "    print(codebook)\n",
        "    dump(kmeans, codeword_save_path + 'kmeans_G.joblib') \n",
        "    np.savez(codeword_save_path + 'codeword_kmeans_G', codeword=codebook, codebooksize=codebooksize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRryEo9l3Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def getImageFeaturesSPM(L, desc, kmeans, k):\n",
        "    W = desc.shape[1]\n",
        "    H = desc.shape[0]   \n",
        "    h = []\n",
        "    for l in range(L+1):\n",
        "        w_step = math.floor(W/(2**l))\n",
        "        h_step = math.floor(H/(2**l))\n",
        "        x, y = 0, 0\n",
        "        for i in range(1,2**l + 1):\n",
        "            x = 0\n",
        "            for j in range(1, 2**l + 1):             \n",
        "                \n",
        "                curr_desc = np.reshape(desc[y:y+h_step, x:x+w_step],(-1,128))\n",
        "                predict = kmeans.predict(curr_desc)\n",
        "                histo = np.bincount(predict, minlength=k).reshape(1,-1).ravel()\n",
        "                weight = 2**(l-L)\n",
        "                h.append(weight*histo)\n",
        "                x = x + w_step\n",
        "            \n",
        "            y = y + h_step\n",
        "    \n",
        "    hist = np.array(h).ravel()\n",
        "    # normalize hist\n",
        "    #dev = np.std(hist)\n",
        "    #hist -= np.mean(hist)\n",
        "    #hist /= dev\n",
        "    return hist\n",
        "\n",
        "def getHistogramSPM(L, data, kmeans, k):    \n",
        "    x = []\n",
        "\n",
        "    for i in tqdm.tqdm(range(len(data))):        \n",
        "        hist = getImageFeaturesSPM(L, data[i], kmeans, k)        \n",
        "        x.append(hist)\n",
        "    return np.array(x)\n",
        "\n",
        "if os.path.isfile(feats_save_path + 'v2/pyramid_histo_G.npz'):\n",
        "    savez_load = np.load(feats_save_path + 'v2/pyramid_histo_G.npz')\n",
        "    train_histo = savez_load['train_histo']\n",
        "    test_histo = savez_load['test_histo']\n",
        "else:\n",
        "    train_histo = getHistogramSPM(2, np.reshape(trainFeats,(-1,32,32,128)), kmeans, codebooksize)\n",
        "    test_histo = getHistogramSPM(2, np.reshape(testFeats,(-1,32,32,128)), kmeans, codebooksize)\n",
        "    np.savez(feats_save_path + 'v2/pyramid_histo_G', train_histo=train_histo, test_histo=test_histo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE7_ga64n_H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize histograms\n",
        "scaler = preprocessing.StandardScaler().fit(train_histo)\n",
        "train_histo_ = scaler.transform(train_histo)\n",
        "test_histo_ = scaler.transform(test_histo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVjb8Wdy9iP6",
        "colab_type": "code",
        "outputId": "041a4c85-9bb3-42c7-b31d-1b52526d1d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_histo.shape)\n",
        "print(test_histo.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3030, 4200)\n",
            "(1692, 4200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaQ04TrQymeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def histogramIntersection(M, N):\n",
        "    m = M.shape[0]\n",
        "    n = N.shape[0]\n",
        "    result = np.zeros((m,n))\n",
        "    for i in tqdm.tqdm(range(m)):\n",
        "        for j in range(n):\n",
        "            temp = np.sum(np.minimum(M[i], N[j]))\n",
        "            result[i][j] = temp\n",
        "    return result\n",
        "if os.path.isfile(feats_save_path + 'v2/gramMatrix__G.npz'):\n",
        "    savez_load = np.load(feats_save_path + 'v2/gramMatrix__G.npz')\n",
        "    trainGramMatrix = savez_load['trainGramMatrix']\n",
        "    testGramMatrix = savez_load['testGramMatrix']\n",
        "else:\n",
        "    trainGramMatrix = histogramIntersection(train_histo_, train_histo_)\n",
        "    testGramMatrix = histogramIntersection(test_histo_, train_histo_)\n",
        "    np.savez(feats_save_path + 'v2/gramMatrix__G', trainGramMatrix=trainGramMatrix, testGramMatrix=testGramMatrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtezCyjzULxU",
        "colab_type": "code",
        "outputId": "93f4b8df-e128-4966-8c8d-dbf28c2613cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trainGramMatrix.shape)\n",
        "print(testGramMatrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3030, 3030)\n",
            "(1692, 3030)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bpBDE-2ciqr0",
        "outputId": "a82e4c0d-ceb0-4969-8063-4208601591f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model = SVC(random_state=0, kernel = 'precomputed') #\n",
        "model.fit(trainGramMatrix, trainLabel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='precomputed', max_iter=-1, probability=False, random_state=0,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rixfOqXW62fc",
        "outputId": "949a049e-fedf-4bf0-854b-d8818d6cd5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = model.predict(trainGramMatrix)\n",
        "print (\"Accuracy:\", np.mean(train == trainLabel)*100, \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vSzIsRdq62ff",
        "colab": {}
      },
      "source": [
        "predict = model.predict(testGramMatrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RTdkgDPa62fh",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({\"Id\":filename,\"Category\":predict})\n",
        "df.index = np.arange(1,len(df)+1)\n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/pattern/repo/pyramid/buffer/results_191213_word200.csv',index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VseBw_Hw__f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}